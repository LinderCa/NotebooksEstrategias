{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2b9a8e9",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [4]</a>'.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1e400e-66ea-4231-b554-33216632364e",
   "metadata": {
    "papermill": {
     "duration": 0.002424,
     "end_time": "2025-06-16T20:17:36.220426",
     "exception": false,
     "start_time": "2025-06-16T20:17:36.218002",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Descarga Realtime Alpha Vantage\n",
    "###### Descarga cada 10 minutos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a59056cd-968d-485d-84e7-d0777e5435ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-16T20:17:36.225080Z",
     "iopub.status.busy": "2025-06-16T20:17:36.224742Z",
     "iopub.status.idle": "2025-06-16T20:17:36.452718Z",
     "shell.execute_reply": "2025-06-16T20:17:36.452032Z"
    },
    "papermill": {
     "duration": 0.231511,
     "end_time": "2025-06-16T20:17:36.453927",
     "exception": false,
     "start_time": "2025-06-16T20:17:36.222416",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "#import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import date, datetime,timedelta\n",
    "#from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b213c3ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-16T20:17:36.459154Z",
     "iopub.status.busy": "2025-06-16T20:17:36.458721Z",
     "iopub.status.idle": "2025-06-16T20:17:36.463259Z",
     "shell.execute_reply": "2025-06-16T20:17:36.462812Z"
    },
    "papermill": {
     "duration": 0.007988,
     "end_time": "2025-06-16T20:17:36.464123",
     "exception": false,
     "start_time": "2025-06-16T20:17:36.456135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo no existe. Se creó un DataFrame vacío.\n"
     ]
    }
   ],
   "source": [
    "# Verificar si el archivo existe\n",
    "ruta_archivo='data/dataxd.txt'\n",
    "if os.path.exists(ruta_archivo):\n",
    "    # Cargar el archivo\n",
    "    df1 = pd.read_csv(ruta_archivo, sep='\\t')\n",
    "    print(\"Archivo cargado correctamente.\")\n",
    "else:\n",
    "    # Crear un DataFrame vacío\n",
    "    df1 = pd.DataFrame()\n",
    "    print(\"Archivo no existe. Se creó un DataFrame vacío.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4377b8ac-a9ef-4fa4-88fc-48d9332e4a08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-16T20:17:36.468884Z",
     "iopub.status.busy": "2025-06-16T20:17:36.468546Z",
     "iopub.status.idle": "2025-06-16T20:17:36.472240Z",
     "shell.execute_reply": "2025-06-16T20:17:36.471773Z"
    },
    "papermill": {
     "duration": 0.006962,
     "end_time": "2025-06-16T20:17:36.473065",
     "exception": false,
     "start_time": "2025-06-16T20:17:36.466103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo no existe. Se creó un DataFrame vacío.\n"
     ]
    }
   ],
   "source": [
    "ruta_archivo='data/dataxh.txt'\n",
    "if os.path.exists(ruta_archivo):\n",
    "    # Cargar el archivo\n",
    "    df2 = pd.read_csv(ruta_archivo, sep='\\t')\n",
    "    print(\"Archivo cargado correctamente.\")\n",
    "else:\n",
    "    # Crear un DataFrame vacío\n",
    "    df2 = pd.DataFrame()\n",
    "    print(\"Archivo no existe. Se creó un DataFrame vacío.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ddb4f4",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d91bdb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-16T20:17:36.477983Z",
     "iopub.status.busy": "2025-06-16T20:17:36.477641Z",
     "iopub.status.idle": "2025-06-16T20:17:36.986471Z",
     "shell.execute_reply": "2025-06-16T20:17:36.985679Z"
    },
    "papermill": {
     "duration": 0.512392,
     "end_time": "2025-06-16T20:17:36.987434",
     "exception": true,
     "start_time": "2025-06-16T20:17:36.475042",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'datetime'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[43mdf1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdatetime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m      2\u001b[0m df2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/usr/share/miniconda/envs/test/lib/python3.10/site-packages/pandas/core/frame.py:4107\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4107\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4109\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/usr/share/miniconda/envs/test/lib/python3.10/site-packages/pandas/core/indexes/range.py:417\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[0;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'datetime'"
     ]
    }
   ],
   "source": [
    "df1['datetime'] = pd.to_datetime(df1['datetime'])\n",
    "df2['datetime'] = pd.to_datetime(df2['datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f9d0f6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_day1 = (df1['datetime'].max()).date()\n",
    "max_day2 = (df2['datetime'].max()).date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c70c3d5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_day2 = max_day2 - timedelta(days=5) #para Realtime restar 5 dias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c159857",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#today = date.today()\n",
    "max_day_str2 = str(max_day2)\n",
    "max_day_str1 = str(max_day1)\n",
    "tickers = [\n",
    "    'SPY',\n",
    "    'META',\n",
    "    'AAPL',\n",
    "    'AMZN',\n",
    "    'NFLX',\n",
    "    'MRNA',\n",
    "    'TSLA',\n",
    "    'TNA',\n",
    "    'GLD',\n",
    "    'SLV',\n",
    "    'USO',\n",
    "    'BAC',\n",
    "    'CVX',\n",
    "    'XOM',\n",
    "    'QQQ',\n",
    "    'MSFT',\n",
    "    'NVDA',\n",
    "    'WMT',\n",
    "    'BA',\n",
    "    'DIS',\n",
    "    'CAT',\n",
    "    'IBM',\n",
    "    'WFC',\n",
    "    'PLTR',\n",
    "    'AMD',\n",
    "    'AVGO',\n",
    "    'HOOD',\n",
    "    'CRWV',\n",
    "    'MSTR',\n",
    "    'UNH',\n",
    "    'GOOG',\n",
    "    'APP',\n",
    "    'UBER'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1193ed69",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#INFORMACION DIAS\n",
    "df_new1 = pd.DataFrame()\n",
    "df_new1 = df1.copy()\n",
    "for ticker in tickers:\n",
    "    url1='https://www.alphavantage.co/query?function=TIME_SERIES_DAILY_ADJUSTED&symbol='+str(ticker)+'&entitlement=delayed&apikey=HR9C4MJVM7O4UUCM&datatype=csv'\n",
    "    company = pd.read_csv(url1, sep=',')\n",
    "    company=company.rename(columns={'timestamp':'datetime','open': 'Open', 'high': 'High', 'low': 'Low', 'close': 'Close', 'volume': 'Volume'})\n",
    "    company = company.drop(['adjusted_close','dividend_amount','split_coefficient'], axis=1)\n",
    "    company['companyName']=ticker\n",
    "    company = company[['Close', 'High', 'Low', 'Open', 'Volume', 'datetime', 'companyName']] #ordenar columnas\n",
    "    company['datetime'] = pd.to_datetime(company['datetime'])\n",
    "    company_lastday = company[company['datetime']>max_day_str1]\n",
    "    df_new1 = pd.concat([df_new1, company_lastday],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca35012-6da3-4775-8beb-b59a5cc61ce4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Funcion limpiar OUTLIERS\n",
    "def df_limpiar(df_eval):\n",
    "    #dataframe para obtener medias sin incluir fecha actual\n",
    "    df_eval2 = df_eval[df_eval['datetime']<max_day_str2].tail(100)\n",
    "    \n",
    "    meandif1 = df_eval2['dif1'].mean()\n",
    "    stddif1 = df_eval2['dif1'].std()\n",
    "    topdif1 = meandif1 + stddif1 * 1.96\n",
    "\n",
    "    meandif2 = df_eval2['dif2'].mean()\n",
    "    stddif2 = df_eval2['dif2'].std()\n",
    "    topdif2 = meandif2 + stddif2 * 1.96\n",
    "    \n",
    "    #botdif = meandif - stddif * 3\n",
    "    copydf = df_eval.copy()\n",
    "    \n",
    "    #df_h.apply(lambda row: row['High'] - row['Close'] if row['Close'] > row['Open'] else row['High'] - row['Open'], axis=1)\n",
    "    copydf['ind1'] = copydf.apply(lambda row: 1 if row['dif1'] > topdif1 else 0, axis=1)\n",
    "    copydf['ind2'] = copydf.apply(lambda row: 1 if row['dif2'] > topdif2 else 0, axis=1)\n",
    "\n",
    "    #hoy = datetime.now()    \n",
    "    #mes_actual = hoy.replace(day=1)\n",
    "    #mes_fin = mes_actual - relativedelta(months=3)\n",
    "    #hace_12_meses = mes_actual - relativedelta(months=12)\n",
    "    #cuartil 3\n",
    "    q3_dif1 = copydf[copydf['ind1']!=1]['dif1'].quantile(0.75)\n",
    "    q3_dif2 = copydf[copydf['ind2']!=1]['dif2'].quantile(0.75)\n",
    "    \n",
    "    #meanfin1 = copydf[(copydf['ind1']==1) & (copydf['datetime'] >= hace_12_meses) & (copydf['datetime'] < mes_fin)]['dif1'].mean()\n",
    "    #meanfin2 = copydf[(copydf['ind2']==1) & (copydf['datetime'] >= hace_12_meses) & (copydf['datetime'] < mes_fin)]['dif2'].mean()\n",
    "\n",
    "    print(\"q3_dif1:\",q3_dif1)\n",
    "    print(\"q3_dif2:\",q3_dif2)\n",
    "\n",
    "    copydf['High2']=copydf.apply(\n",
    "        lambda row: row['Close'] + q3_dif1 if (row['Close'] > row['Open']) & (row['ind1']==1) & (row['eval']==0)  else \n",
    "        row['Open'] + q3_dif1 if (row['Close'] <= row['Open']) & (row['ind1']==1) & (row['eval']==0) else\n",
    "        row['High'], axis=1)\n",
    "    copydf['Low2']=copydf.apply(\n",
    "        lambda row: row['Open'] - q3_dif2 if (row['Close'] > row['Open']) & (row['ind2']==1) & (row['eval']==0) else \n",
    "        row['Close'] - q3_dif2 if (row['Close'] <= row['Open']) & (row['ind2']==1) & (row['eval']==0) else\n",
    "        row['Low'], axis=1)\n",
    "   \n",
    "    #copydf = copydf.drop(copydf[copydf['dif1'] > topdif1].index)\n",
    "    #copydf = copydf.drop(copydf[copydf['dif2'] > topdif2].index)\n",
    "    return copydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45de6ea8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_new2 = pd.DataFrame()\n",
    "for ticker in tickers:\n",
    "    #Informacion anterior por ticker\n",
    "    df_ticker = df2[(df2['datetime'] <  max_day_str2) & (df2['companyName']==ticker)]\n",
    "    df_ticker = df_ticker.reset_index(drop=True)\n",
    "    df_ticker['datetime'] = pd.to_datetime(df_ticker['datetime'])\n",
    "    #crear columnas de diferencia\n",
    "    df_ticker['dif1'] = df_ticker.apply(lambda row: row['High'] - row['Close'] if row['Close'] > row['Open'] else row['High'] - row['Open'], axis=1)\n",
    "    df_ticker['dif2'] = df_ticker.apply(lambda row: row['Open'] - row['Low'] if row['Close'] > row['Open'] else row['Close'] - row['Low'], axis=1)\n",
    "    df_ticker['eval'] = 1 #no se limpiara\n",
    "    #Aplha vantage descarga intraday\n",
    "    url='https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY&symbol=' + str(ticker)+ '&interval=60min&entitlement=delayed&apikey=HR9C4MJVM7O4UUCM&datatype=csv'\n",
    "    company = pd.read_csv(url, sep=',')         \n",
    "    company = company[['close','high','low','open','volume','timestamp']]\n",
    "    company=company.rename(columns={\"open\": \"Open\",\"high\": \"High\",\"low\": \"Low\",\"close\": \"Close\",\"volume\": \"Volume\",\"timestamp\": \"datetime\"})        \n",
    "    company['companyName']=ticker\n",
    "    company['datetime'] = pd.to_datetime(company['datetime'])\n",
    "    company['datetime'] = company['datetime'].dt.tz_localize('UTC')\n",
    "    #company['datetime'] = company['datetime'].dt.tz_localize('US/Eastern')\n",
    "    company_lastday = company[company['datetime']>=max_day_str2]\n",
    "    company_lastday = company_lastday.sort_values(by=['datetime'], ascending=[True])\n",
    "    \n",
    "    #crear columnas diferencia de las colas (se evaluara el ultimo dia)\n",
    "    company_lastday['dif1'] = company_lastday.apply(lambda row: row['High'] - row['Close'] if row['Close'] > row['Open'] else row['High'] - row['Open'], axis=1)\n",
    "    company_lastday['dif2'] = company_lastday.apply(lambda row: row['Open'] - row['Low'] if row['Close'] > row['Open'] else row['Close'] - row['Low'], axis=1)\n",
    "    company_lastday['eval'] = 0 # se limpiara    \n",
    "    df_ticker = pd.concat([df_ticker, company_lastday],ignore_index=True)    \n",
    "    company_final = df_limpiar(df_ticker)    \n",
    "    df_new2 = pd.concat([df_new2, company_final],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ab14cb",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_new2['High'] = np.where(df_new2['eval'] == 0, df_new2['High2'], df_new2['High'])\n",
    "df_new2['Low'] = np.where(df_new2['eval'] == 0, df_new2['Low2'], df_new2['Low'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c615c99e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_new2 = df_new2.drop(columns=['dif1', 'dif2', 'eval', 'ind1', 'ind2', 'High2','Low2' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26f0e91-cf20-463d-905e-7d63bfcbf0b0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#descarga de informacion, estrategia: RUPTURA DEL CANAL BAJISTA\n",
    "path='data/dataxd.txt'\n",
    "folder=os.path.dirname(path)\n",
    "\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)\n",
    "\n",
    "if os.path.exists(path):\n",
    "    # delete the file\n",
    "    os.remove(path)\n",
    "else:\n",
    "    # if the file does not exist.\n",
    "    print(\"File does not exists. File needs to be created.\")\n",
    "\n",
    "#export DataFrame to text file\n",
    "with open(path, 'a') as f:\n",
    "    #df_string = appl_hor3.to_string(header=True, index=False, sep ='\\t')\n",
    "    df_new1.to_csv(path, header=True, index=None, sep='\\t', mode='w')\n",
    "    #f.write(df_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adc5089",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#descarga de informacion\n",
    "path='data/dataxh.txt'\n",
    "# check whether the file exists\n",
    "if os.path.exists(path):\n",
    "    # delete the file\n",
    "    os.remove(path)\n",
    "else:\n",
    "    # if the file does not exist.\n",
    "    print(\"File does not exists. File needs to be created.\")\n",
    "\n",
    "#export DataFrame to text file\n",
    "with open(path, 'a') as f:\n",
    "    #df_string = appl_hor3.to_string(header=True, index=False, sep ='\\t')\n",
    "    df_new2.to_csv(path, header=True, index=None, sep='\\t', mode='w')\n",
    "    #f.write(df_string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1.808954,
   "end_time": "2025-06-16T20:17:37.306473",
   "environment_variables": {},
   "exception": true,
   "input_path": "downLoadDataRealtimeAlpha.ipynb",
   "output_path": "downLoadDataRealtimeAlpha_out.ipynb",
   "parameters": {},
   "start_time": "2025-06-16T20:17:35.497519",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}